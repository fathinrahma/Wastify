{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 20:55:59.236353: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.applications.xception as xception\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 320    \n",
    "IMAGE_HEIGHT = 320\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "\n",
    "# Path where our data is located\n",
    "base_path = r'/Users/fathinrahma/Downloads/garbage_classification/'\n",
    "\n",
    "# Dictionary to save our 12 classes\n",
    "categories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'trash', 5: 'battery',\n",
    "              6: 'shoes', 7: 'clothes', 8: 'green-glass', 9: 'brown-glass', 10: 'white-glass',\n",
    "              11: 'biological'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements =  15515\n"
     ]
    }
   ],
   "source": [
    "def add_class_name_prefix(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '/' + x)\n",
    "    return df\n",
    "\n",
    "# list conatining all the filenames in the dataset\n",
    "filenames_list = []\n",
    "# list to store the corresponding category, note that each folder of the dataset has one class of data\n",
    "categories_list = []\n",
    "\n",
    "for category in categories:\n",
    "    filenames = os.listdir(base_path + categories[category])\n",
    "    \n",
    "    filenames_list = filenames_list  +filenames\n",
    "    categories_list = categories_list + [category] * len(filenames)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames_list,\n",
    "    'category': categories_list\n",
    "})\n",
    "\n",
    "df = add_class_name_prefix(df, 'filename')\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('number of elements = ' , len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 320, 320, 3)       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 10, 10, 2048)      20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                24588     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,886,068\n",
      "Trainable params: 24,588\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "import keras.applications.xception as xception\n",
    "\n",
    "xception_layer = xception.Xception(include_top = False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "                       weights = 'imagenet')\n",
    "\n",
    "# We don't want to train the imported weights\n",
    "xception_layer.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "\n",
    "#create a custom layer to apply the preprocessing\n",
    "def xception_preprocessing(img):\n",
    "  return xception.preprocess_input(img)\n",
    "\n",
    "model.add(Lambda(xception_preprocessing))\n",
    "\n",
    "model.add(xception_layer)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(Dense(len(categories), activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_categorical_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n",
    "\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size =  1551 validate size =  1551 test size =  1552\n"
     ]
    }
   ],
   "source": [
    "df[\"category\"] = df[\"category\"].replace(categories) \n",
    "\n",
    "# We first split the data into two sets and then split the validate_df to two sets\n",
    "train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "validate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12412 validated image filenames belonging to 12 classes.\n",
      "Found 1551 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    \n",
    "    ###  Augmentation Start  ###\n",
    "    \n",
    "    #rotation_range=30,\n",
    "    #shear_range=0.1,\n",
    "    #zoom_range=0.3,\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip = True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2\n",
    "    \n",
    "    ##  Augmentation End  ###\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_datagen = image.ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/ipykernel_78910/2716048666.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 20:56:23.935600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - ETA: 0s - loss: 0.6090 - categorical_accuracy: 0.8412 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 23:13:06.643033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 9148s 47s/step - loss: 0.6090 - categorical_accuracy: 0.8412 - val_loss: 0.2909 - val_categorical_accuracy: 0.9284\n",
      "Epoch 2/20\n",
      "193/193 [==============================] - 7434s 39s/step - loss: 0.2344 - categorical_accuracy: 0.9407 - val_loss: 0.2294 - val_categorical_accuracy: 0.9362\n",
      "Epoch 3/20\n",
      "193/193 [==============================] - 5618s 29s/step - loss: 0.1787 - categorical_accuracy: 0.9517 - val_loss: 0.2023 - val_categorical_accuracy: 0.9414\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 6216s 32s/step - loss: 0.1493 - categorical_accuracy: 0.9594 - val_loss: 0.1922 - val_categorical_accuracy: 0.9434\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 5564s 29s/step - loss: 0.1285 - categorical_accuracy: 0.9648 - val_loss: 0.1783 - val_categorical_accuracy: 0.9518\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 6211s 32s/step - loss: 0.1124 - categorical_accuracy: 0.9704 - val_loss: 0.1766 - val_categorical_accuracy: 0.9499\n",
      "Epoch 7/20\n",
      "193/193 [==============================] - ETA: 0s - loss: 0.1011 - categorical_accuracy: 0.9729 Restoring model weights from the end of the best epoch: 5.\n",
      "193/193 [==============================] - 6446s 33s/step - loss: 0.1011 - categorical_accuracy: 0.9729 - val_loss: 0.1726 - val_categorical_accuracy: 0.9505\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'/Users/fathinrahma/Downloads/transfer_learning.h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('/Users/fathinrahma/Downloads/transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 41). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/tmpz0sfcnx9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/tmpz0sfcnx9/assets\n",
      "2023-06-05 15:50:48.926727: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-06-05 15:50:48.926757: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-06-05 15:50:48.927331: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/tmpz0sfcnx9\n",
      "2023-06-05 15:50:48.985460: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-05 15:50:48.985490: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/tmpz0sfcnx9\n",
      "2023-06-05 15:50:49.230191: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-06-05 15:50:50.308355: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/g4/c07sgvs57wvfkh2285l6sdrh0000gn/T/com.apple.sharingd/tmpz0sfcnx9\n",
      "2023-06-05 15:50:50.667101: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 1739777 microseconds.\n"
     ]
    }
   ],
   "source": [
    "keras_file = '/Users/fathinrahma/Downloads/transfer_learning.h5'\n",
    "tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "# Convert to TensorFlow Lite model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "tflite_file = '/Users/fathinrahma/Downloads/transfer_learning.tflite'\n",
    "with open(tflite_file, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1fe2c5c7caffba53fe4353ed4a6eae192ae31d1786148aaf85a33071428c154"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
